{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MJa_39hTVWL"
      },
      "source": [
        "### 데이터 분할을 위한 폴더 생성"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFJ6TSzFTfmx",
        "outputId": "d98ad1a4-6dab-42fb-9ebd-83f8e7193478"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMvAlOjBTVWP"
      },
      "source": [
        "### 베이스라인 모델 학습을 위한 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idX-zhCoTVWP",
        "outputId": "14082bee-7eb3-4b84-9195-5c70bc4218e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# MPS 지원 여부 확인\n",
        "USE_MPS = torch.backends.mps.is_available()  # MPS 지원 여부\n",
        "USE_CUDA = torch.cuda.is_available()        # CUDA 지원 여부\n",
        "\n",
        "# 디바이스 선택 (MPS > CUDA > CPU 순으로 우선 선택)\n",
        "if USE_MPS:\n",
        "    DEVICE = torch.device(\"mps\")\n",
        "elif USE_CUDA:\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "EPOCH = 30\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY-5YnIuTVWS"
      },
      "source": [
        "### VisonTransformer를 위한 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mLsTk0raTVWS"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "VIT_BATCH_SIZE = 64\n",
        "\n",
        "vit_transform_base = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5],[0.5])\n",
        "])\n",
        "\n",
        "vit_train_dataset = ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/splitted/train',transform=vit_transform_base)\n",
        "vit_val_dataset = ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/splitted/val',transform=vit_transform_base)\n",
        "\n",
        "vit_train_loader = DataLoader(vit_train_dataset, batch_size=VIT_BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "vit_val_loader = DataLoader(vit_val_dataset, batch_size=VIT_BATCH_SIZE, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ft9-JQQTVWT"
      },
      "source": [
        "### VisonTransformer 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "S_oj8xE4TVWT"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.vision_transformer import vit_b_16\n",
        "\n",
        "class ViTClassifier(nn.Module):\n",
        "    def __init__(self, num_classes = 33):\n",
        "        super(ViTClassifier, self).__init__()\n",
        "        self.vit = vit_b_16(weights = None)\n",
        "        self.vit.heads = nn.Linear(768, num_classes)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.vit(x)\n",
        "\n",
        "model_vit = ViTClassifier(num_classes=len(vit_train_dataset.classes)).to(DEVICE)\n",
        "optimizer = optim.Adam(model_vit.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW2l4fatTVWT"
      },
      "source": [
        "### VisonTransformer 학습 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dlQR2cVbTVWT"
      },
      "outputs": [],
      "source": [
        "def vit_train(model, train_loader, optimizer):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = nn.CrossEntropyLoss()(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4jx6cn1TVWT"
      },
      "source": [
        "### VisonTransformer 평가 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wR7E3vAFTVWT"
      },
      "outputs": [],
      "source": [
        "def vit_evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data,target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(data)\n",
        "            test_loss += nn.CrossEntropyLoss()(output, target).item()\n",
        "            pred = output.argmax(dim = 1, keepdim = True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100 * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQsi7GieTVWU"
      },
      "source": [
        "### VisonTransformer 모델 학습 하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAke0xi5TVWU",
        "outputId": "8e5bac98-29a1-4362-f2e2-42537f672022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------- epoch 1 ----------------\n",
            "train Loss: 0.0344, Accuracy: 34.90%\n",
            "val Loss: 0.0346, Accuracy: 34.16%\n",
            "Completed in 22m 35s\n"
          ]
        }
      ],
      "source": [
        "def vit_train_baseline(model, train_loader, val_loader, optimizer, num_epochs = EPOCH):\n",
        "    best_acc = 0.0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        since = time.time()\n",
        "        vit_train(model, train_loader, optimizer)\n",
        "        train_loss, train_acc = vit_evaluate(model, train_loader)\n",
        "        val_loss, val_acc = vit_evaluate(model, val_loader)\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'-------------- epoch {epoch} ----------------')\n",
        "        print(f'train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%')\n",
        "        print(f'val Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%')\n",
        "        print(f'Completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "vit_model = vit_train_baseline(model_vit, vit_train_loader, vit_val_loader, optimizer, EPOCH)\n",
        "torch.save(vit_model, 'vit_model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCJD3WS6TVWW"
      },
      "source": [
        "### VisionTransformer 모델 평가를 위한 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HnAOwg8TVWW"
      },
      "outputs": [],
      "source": [
        "test_dataset = ImageFolder(root='/content/drive/MyDrive/Colab Notebooks/splitted/test', transform=vit_transform_base)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaxvUAFVTVWX"
      },
      "source": [
        "### Vision Transformer 모델 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWBKyiYTTVWX"
      },
      "outputs": [],
      "source": [
        "vit_model = torch.load('vit_model.pt')\n",
        "vit_model.eval()\n",
        "test_loss, test_accuracy = vit_evaluate(vit_model, test_loader)\n",
        "print('ViT test acc: ',test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cq0GKQgUIUV8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}